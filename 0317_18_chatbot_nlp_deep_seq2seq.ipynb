{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0317-18_chatbot_nlp_deep_seq2seq",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nbRSdgCf9Do",
        "outputId": "3a91ab27-0239-47e5-8c72-33d730b0e010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRpGiS4qhbSO",
        "outputId": "2137891c-d79e-4ba8-9500-a48de6edc77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/requirements.txt' ."
      ],
      "metadata": {
        "id": "Dwlt4h1mhc35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VS8Qmm-hfLl",
        "outputId": "ec099792-7a5d-4a58-99af-f2972beb7f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  requirements.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAQ7RaVBhsZi",
        "outputId": "9063051b-dd5f-4aef-cee2-add2dca82d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy==0.6.0\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 3.9 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 66.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy==0.6.0->-r requirements.txt (line 1)) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy==0.6.0->-r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy==0.6.0->-r requirements.txt (line 1)) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdHjKGSAgTav",
        "outputId": "6e989db9-d6f0-44a5-c024-382a658005b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "konlpy==0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRccKS5rfBl_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Embedding, GRU, Dense\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/\")\n",
        "\n",
        "from preprocess import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ua7g1Tl2gJPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_IN_PATH = '/content/drive/MyDrive/data_in/'\n",
        "DATA_OUT_PATH = '/content/drive/MyDrive/data_out/'\n",
        "TRAIN_INPUTS = 'train_inputs.npy'\n",
        "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
        "TRAIN_TARGETS = 'train_targets.npy'\n",
        "DATA_CONFIGS = 'data_configs.json'"
      ],
      "metadata": {
        "id": "v2U_0wOeipOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED_NUM = 1234\n",
        "tf.random.set_seed(SEED_NUM)"
      ],
      "metadata": {
        "id": "Pd4F6F8Ki8ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
        "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n",
        "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n",
        "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
      ],
      "metadata": {
        "id": "1o9uAafEjBPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(index_inputs),  len(index_outputs), len(index_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn60C6xxjMi-",
        "outputId": "9d89336e-05ce-4b86-b088-e4a5549e20ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 20 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'seq2seq_kor'\n",
        "BATCH_SIZE = 2\n",
        "MAX_SEQUENCE = 25\n",
        "EPOCH = 30\n",
        "UNITS = 1024\n",
        "EMBEDDING_DIM = 256\n",
        "VALIDATION_SPLIT = 0.1 \n",
        "\n",
        "char2idx = prepro_configs['char2idx']\n",
        "idx2char = prepro_configs['idx2char']\n",
        "std_index = prepro_configs['std_symbol']\n",
        "end_index = prepro_configs['end_symbol']\n",
        "vocab_size = prepro_configs['vocab_size']"
      ],
      "metadata": {
        "id": "PY0AmnqGju6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "      x = self.embedding(x)\n",
        "      output, state = self.gru(x, initial_state=hidden)\n",
        "      return output, state\n",
        "\n",
        "    def initialize_hidden_state(self, inp):\n",
        "      \n",
        "      return tf.zeros((tf.shape(inp)[0], self.enc_units))"
      ],
      "metadata": {
        "id": "Sw9OJEQFj6nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "2lhyHThdnO8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd_1da7HoSPK",
        "outputId": "25d57f57-626d-4a54-c772-66091f4faa02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_hidden = encoder.initialize_hidden_state(index_inputs)\n",
        "enc_hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4lVe3nvo01o",
        "outputId": "6710ba97-a06f-420e-de4f-2b59d1a8c314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([20, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahdanau Attention"
      ],
      "metadata": {
        "id": "k9x62Vphxpz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "\n",
        "    self.W1 = Dense(units) #입력과 w\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1) #output\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # expand_dim: \n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    #하이퍼볼릭 함수 지나도록 함\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    #softmax\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    #softmax한 걸 기존거랑 곱해줘야 함: context_vector\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "sgdmpiclxSzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "디코더(seq2seq 교안 p.15)"
      ],
      "metadata": {
        "id": "IbooNm0lxruu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "    #GRU: 입력으로 들어온 애가 타임스텝별로 그 아웃풋 사용\n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # hidden state 나온 걸로 단어 맞춰야 함\n",
        "    self.fc = Dense(self.vocab_size) #출력을 vocab_size -> softmax -> crossentropy -> 가장 높은 라벨 중 하나를 고름\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  #x: decoder의 input, hidden: 어텐션 스코어, enc_output: 마지막 단계\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    #입력이 들어가기 전에 어텐션 거는 것\n",
        "    #교안예시는 입력이 들어간 다음, 나중에 어텐션을 걸었음\n",
        "    output, state = self.gru(x)\n",
        "    output = tf.reshape(output, (-1, output.shape[2])) #shape 맞추기\n",
        "\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "metadata": {
        "id": "-98Nv1duuY3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# CategoricalCrossentropy : 다중 클래스 분류(원핫)\n",
        "# SparseCategoricalCrossentropy: 다중 클래스 분류(라벨; softmax가 이미 그안에 들어가있음)\n",
        "# reduction: sample의 개수 더해주는 것\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "\n",
        "# real: target, pred: model 결과\n",
        "def loss(real, pred):\n",
        "  # 문장 가져오면 char2idx, idx2char에서 바꿔줌\n",
        "  # index:0 = <PAD> -> 원래 문자 없는거니까 loss 계산 안하려고 masking(얘의 loss값 안쓰겠다)\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred) #loss구하기\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  # expand_dims: 차원 바꿔주는 것\n",
        "  mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
        "  pred *= mask\n",
        "  acc = train_accuracy(real, pred)\n",
        "\n",
        "  return tf.reduce_mean(acc)"
      ],
      "metadata": {
        "id": "_W9mEHnO3gXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq2seq model: encoder, decoder 두개 갖고 있는 모델\n",
        "class seq2seq(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz, end_token_idx=2):\n",
        "        super(seq2seq, self).__init__()\n",
        "        self.end_token_idx = end_token_idx\n",
        "        # 언어 하나라 인코더, 디코더 vocab_size 같게 둔 것(언어 달라지면 이거 변경)\n",
        "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz)\n",
        "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz)\n",
        "\n",
        "    def call(self, x):\n",
        "      # enc_input: encoder의 입력, dec_input: decoder의 입력\n",
        "      enc_inputs, dec_inputs = x\n",
        "\n",
        "      #encoder에 집어넣기\n",
        "      enc_hidden = self.encoder.initialize_hidden_state(enc_inputs)\n",
        "      #enc_hidden: encoder 마지막 단의 hidden state\n",
        "      enc_output, enc_hidden = self.encoder(enc_inputs, enc_hidden)\n",
        "\n",
        "      #enc_hidden: context vector\n",
        "      dec_hidden = enc_hidden\n",
        "\n",
        "      predict_tokens = []\n",
        "      #sequence length만큼 돌아가도록\n",
        "      for t in range(dec_inputs.shape[1]):\n",
        "        #sample: 20개, sequence length: 25\n",
        "        #단어 순서대로 가져오기; 단어 rnn에 집어넣기\n",
        "        dec_input = tf.dtypes.cast(tf.expand_dims(dec_inputs[:, t], 1), tf.float32)\n",
        "        # 앞(gru)에서 3개 리턴했으니까 자리만 맞춰주는 것\n",
        "        # decoder 한번 돌면 dec_hidden에 update된 state 들어가는 것\n",
        "        # dec_input: 잘못된 거 학습하지 않도록 정답 집어넣는 것(teacher forcing)\n",
        "        predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "        predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))\n",
        "    \n",
        "      return tf.stack(predict_tokens, axis=1)"
      ],
      "metadata": {
        "id": "--qWo_iM5Ld1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = seq2seq(vocab_size, EMBEDDING_DIM, UNITS, UNITS, BATCH_SIZE, char2idx[end_index])\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=accuracy)"
      ],
      "metadata": {
        "id": "cc5URgwi12R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([index_inputs, index_outputs], index_targets, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCH, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTYSuuAR2iFx",
        "outputId": "cff61773-f072-4586-b3e7-e4f3d1b29862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "9/9 [==============================] - 77s 4s/step - loss: 1.1481 - accuracy: 0.7758 - val_loss: 1.0959 - val_accuracy: 0.7960\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 1.0665 - accuracy: 0.7942 - val_loss: 0.9627 - val_accuracy: 0.7980\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.9495 - accuracy: 0.8001 - val_loss: 0.8574 - val_accuracy: 0.7987\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.8788 - accuracy: 0.7986 - val_loss: 0.8473 - val_accuracy: 0.7990\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.8177 - accuracy: 0.7993 - val_loss: 0.7936 - val_accuracy: 0.7992\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.7484 - accuracy: 0.7998 - val_loss: 0.7121 - val_accuracy: 0.8010\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.6704 - accuracy: 0.8032 - val_loss: 0.6251 - val_accuracy: 0.8054\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.5886 - accuracy: 0.8094 - val_loss: 0.5314 - val_accuracy: 0.8123\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.5010 - accuracy: 0.8166 - val_loss: 0.4413 - val_accuracy: 0.8211\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.4270 - accuracy: 0.8255 - val_loss: 0.3178 - val_accuracy: 0.8300\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.3594 - accuracy: 0.8350 - val_loss: 0.2900 - val_accuracy: 0.8389\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.2863 - accuracy: 0.8436 - val_loss: 0.2394 - val_accuracy: 0.8477\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.2452 - accuracy: 0.8513 - val_loss: 0.3037 - val_accuracy: 0.8542\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.2237 - accuracy: 0.8572 - val_loss: 0.1632 - val_accuracy: 0.8601\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.1944 - accuracy: 0.8630 - val_loss: 0.2148 - val_accuracy: 0.8655\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.1766 - accuracy: 0.8679 - val_loss: 0.1952 - val_accuracy: 0.8699\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.1619 - accuracy: 0.8722 - val_loss: 0.1803 - val_accuracy: 0.8744\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1713 - accuracy: 0.8764 - val_loss: 0.1856 - val_accuracy: 0.8782\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1673 - accuracy: 0.8803 - val_loss: 0.2370 - val_accuracy: 0.8815\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1528 - accuracy: 0.8832 - val_loss: 0.1863 - val_accuracy: 0.8845\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1478 - accuracy: 0.8861 - val_loss: 0.2012 - val_accuracy: 0.8874\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1343 - accuracy: 0.8888 - val_loss: 0.1785 - val_accuracy: 0.8903\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 24s 3s/step - loss: 0.1159 - accuracy: 0.8917 - val_loss: 0.1719 - val_accuracy: 0.8931\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.1044 - accuracy: 0.8946 - val_loss: 0.2004 - val_accuracy: 0.8959\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0927 - accuracy: 0.8973 - val_loss: 0.1555 - val_accuracy: 0.8985\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0792 - accuracy: 0.8999 - val_loss: 0.1487 - val_accuracy: 0.9011\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0593 - accuracy: 0.9027 - val_loss: 0.1410 - val_accuracy: 0.9039\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0425 - accuracy: 0.9053 - val_loss: 0.1356 - val_accuracy: 0.9066\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0409 - accuracy: 0.9080 - val_loss: 0.1840 - val_accuracy: 0.9091\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 25s 3s/step - loss: 0.0508 - accuracy: 0.9103 - val_loss: 0.4142 - val_accuracy: 0.9112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s3fC4bJs4pNA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}