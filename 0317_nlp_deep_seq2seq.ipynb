{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0317_nlp_deep_seq2seq",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nbRSdgCf9Do",
        "outputId": "3a91ab27-0239-47e5-8c72-33d730b0e010"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRpGiS4qhbSO",
        "outputId": "02abc94a-9028-4a39-c8ee-3419bd4ef662"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/requirements.txt' ."
      ],
      "metadata": {
        "id": "Dwlt4h1mhc35"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VS8Qmm-hfLl",
        "outputId": "59d008d5-98af-4ba0-f449-bf55ec5d2da2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  requirements.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAQ7RaVBhsZi",
        "outputId": "0e29073d-506c-4427-a6c0-69d40ce87cae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy==0.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy==0.6.0->-r requirements.txt (line 1)) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy==0.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy==0.6.0->-r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy==0.6.0->-r requirements.txt (line 1)) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdHjKGSAgTav",
        "outputId": "6e989db9-d6f0-44a5-c024-382a658005b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "konlpy==0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iRccKS5rfBl_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Embedding, GRU\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/\")\n",
        "\n",
        "from preprocess import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ua7g1Tl2gJPX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_IN_PATH = '/content/drive/MyDrive/data_in/'\n",
        "DATA_OUT_PATH = '/content/drive/MyDrive/data_out/'\n",
        "TRAIN_INPUTS = 'train_inputs.npy'\n",
        "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
        "TRAIN_TARGETS = 'train_targets.npy'\n",
        "DATA_CONFIGS = 'data_configs.json'"
      ],
      "metadata": {
        "id": "v2U_0wOeipOA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED_NUM = 1234\n",
        "tf.random.set_seed(SEED_NUM)"
      ],
      "metadata": {
        "id": "Pd4F6F8Ki8ga"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
        "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n",
        "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n",
        "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
      ],
      "metadata": {
        "id": "1o9uAafEjBPp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(index_inputs),  len(index_outputs), len(index_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn60C6xxjMi-",
        "outputId": "1a2abc1a-9111-4833-9f58-dfbb7c90a051"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 20 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'seq2seq_kor'\n",
        "BATCH_SIZE = 2\n",
        "MAX_SEQUENCE = 25\n",
        "EPOCH = 30\n",
        "UNITS = 1024\n",
        "EMBEDDING_DIM = 256\n",
        "VALIDATION_SPLIT = 0.1 \n",
        "\n",
        "char2idx = prepro_configs['char2idx']\n",
        "idx2char = prepro_configs['idx2char']\n",
        "std_index = prepro_configs['std_symbol']\n",
        "end_index = prepro_configs['end_symbol']\n",
        "vocab_size = prepro_configs['vocab_size']"
      ],
      "metadata": {
        "id": "PY0AmnqGju6q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "      x = self.embedding(x)\n",
        "      output, state = self.gru(x, initial_state=hidden)\n",
        "      return output, state\n",
        "\n",
        "    def initialize_hidden_state(self, inp):\n",
        "      \n",
        "      return tf.zeros((tf.shape(inp)[0], self.enc_units))"
      ],
      "metadata": {
        "id": "Sw9OJEQFj6nO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "2lhyHThdnO8i"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd_1da7HoSPK",
        "outputId": "0b9966eb-c218-4b2f-d6f7-3fc67225bc7f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_hidden = encoder.initialize_hidden_state(index_inputs)\n",
        "enc_hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4lVe3nvo01o",
        "outputId": "0802691a-a968-4158-e1a4-046440bed636"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([20, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahdanau Attention"
      ],
      "metadata": {
        "id": "k9x62Vphxpz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "\n",
        "    self.W1 = Dense(units) #입력과 w\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1) #output\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # expand_dim: \n",
        "    hidden_with_time_axis = tf.expand_dim(query, 1)\n",
        "\n",
        "    #하이퍼볼릭 함수 지나도록 함\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    #softmax\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    #softmax한 걸 기존거랑 곱해줘야 함: context_vector\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "sgdmpiclxSzy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "디코더(seq2seq 교안 p.15)"
      ],
      "metadata": {
        "id": "IbooNm0lxruu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.batch_sz = batch_sz\n",
        "    self.decoder_units = dec_units\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "    #GRU: 입력으로 들어온 애가 타임스텝별로 그 아웃풋 사용\n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # hidden state 나온 걸로 단어 맞춰야 함\n",
        "    self.fc = Dense(self.vocab_size) #출력을 vocab_size -> softmax -> crossentropy -> 가장 높은 라벨 중 하나를 고름\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  #x: decoder의 input, hidden: 어텐션 스코어, enc_output: 마지막 단계\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    #입력이 들어가기 전에 어텐션 거는 것\n",
        "    #교안예시는 입력이 들어간 다음, 나중에 어텐션을 걸었음\n",
        "    output, state = self.gru(x)\n",
        "    output = tf.reshape(output, (-1, output.shape[2])) #shape 맞추기\n",
        "\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "metadata": {
        "id": "-98Nv1duuY3P"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_W9mEHnO3gXq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}